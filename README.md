# ğŸ” Image Classifier

**Production-grade multi-class image classification using transfer learning.**  
Built with [fast.ai](https://docs.fast.ai) + PyTorch. ResNet-50 backbone. One command to train, one command to predict.

![CI](https://github.com/YOUR_USERNAME/image-classifier/actions/workflows/ci.yml/badge.svg)
![Python](https://img.shields.io/badge/python-3.9%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![License](https://img.shields.io/badge/license-MIT-green)

---

## âœ¨ Features

| Feature | Detail |
|---|---|
| **Architecture** | ResNet-50 (or 34 / EfficientNet-B0 / B3) |
| **Transfer learning** | ImageNet pretrained â€” works with as few as 50 images/class |
| **Two-phase training** | Freeze â†’ head train â†’ unfreeze â†’ discriminative LR fine-tune |
| **LR finder** | Smith (2017) LR range test â€” no manual LR tuning |
| **Augmentation** | Flip, rotate, zoom, lighting, perspective warp |
| **Regularisation** | MixUp, label smoothing, dropout, AdamW weight decay |
| **Mixed precision** | FP16 on CUDA â€” 2Ã— faster, 2Ã— lower VRAM |
| **Export** | Self-contained `.pkl` â€” single file inference, zero config |
| **REST API** | FastAPI server, Docker-ready |
| **Reproducible** | Fixed random seed across Python / NumPy / PyTorch |

---

## ğŸ—‚ Project Structure

```
image-classifier/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml              â† all hyperparameters
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset/                 â† YOUR images go here
â”‚       â”œâ”€â”€ cat/
â”‚       â”œâ”€â”€ dog/
â”‚       â””â”€â”€ bird/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ exported/
â”‚       â””â”€â”€ classifier.pkl       â† trained model (auto-generated)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config_loader.py         â† typed YAML â†’ dataclass
â”‚   â”œâ”€â”€ data_pipeline.py         â† DataBlock, augmentation, DataLoaders
â”‚   â”œâ”€â”€ model_builder.py         â† Learner, LR finder, export
â”‚   â”œâ”€â”€ trainer.py               â† two-phase training loop
â”‚   â””â”€â”€ utils.py                 â† seed, logging, device, validation
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_sample_data.py  â† zero-prep dataset download
â”‚   â”œâ”€â”€ setup_env.sh             â† one-shot setup (Linux/macOS)
â”‚   â””â”€â”€ setup_env.bat            â† one-shot setup (Windows)
â”‚
â”œâ”€â”€ train.py                     â† training entry point
â”œâ”€â”€ predict.py                   â† inference entry point
â”œâ”€â”€ evaluation.py                â† metrics report
â”œâ”€â”€ api.py                       â† FastAPI REST server
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Makefile
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Quick Start

### Option A â€” One command (Linux / macOS)

```bash
git clone https://github.com/YOUR_USERNAME/image-classifier.git
cd image-classifier
chmod +x scripts/setup_env.sh && ./scripts/setup_env.sh
source .venv/bin/activate
python train.py
```

### Option B â€” One command (Windows)

```bat
git clone https://github.com/YOUR_USERNAME/image-classifier.git
cd image-classifier
scripts\setup_env.bat
.venv\Scripts\activate
python train.py
```

### Option C â€” Make

```bash
git clone https://github.com/YOUR_USERNAME/image-classifier.git
cd image-classifier
make setup      # creates venv, installs deps, downloads data
make train      # trains the model
make predict IMG=data/dataset/cat/cat_000.jpg
```

> **The setup scripts handle everything:** virtual environment, all dependencies,
> and a sample cats/dogs dataset â€” no manual steps required.

---

## ğŸ“¦ Manual Setup (Step by Step)

### 1. Clone

```bash
git clone https://github.com/YOUR_USERNAME/image-classifier.git
cd image-classifier
```

### 2. Create virtual environment

```bash
# Linux / macOS
python3 -m venv .venv
source .venv/bin/activate

# Windows
python -m venv .venv
.venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install --upgrade pip

# GPU (NVIDIA CUDA)
pip install torch torchvision
pip install -r requirements.txt

# CPU only (smaller install, slower training)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
```

### 4. Prepare dataset

**Option A â€” Download the built-in sample dataset (cats + dogs, ~800 MB):**

```bash
python scripts/download_sample_data.py
```

**Option B â€” Download arbitrary classes via Bing:**

```bash
python scripts/download_sample_data.py --classes cat dog bird --limit 200
```

**Option C â€” Use your own images:**

```
data/dataset/
    your_class_1/   img001.jpg  img002.jpg  ...   (â‰¥ 50 images recommended)
    your_class_2/   ...
    your_class_3/   ...
```

> Any image format works: JPEG, PNG, BMP, WebP.  
> Class name = folder name. That's the entire labelling interface.

---

## ğŸ‹ï¸ Training

```bash
# Standard training
python train.py

# Auto-detect best learning rate (recommended for new datasets)
python train.py --lr-finder

# Preview augmented samples before training
python train.py --show-batch

# 1-epoch smoke test (CI / debugging)
python train.py --quick

# Custom config
python train.py --config my_config.yaml
```

**Training output files:**

| File | Contents |
|---|---|
| `models/exported/classifier.pkl` | Deployable model (weights + vocab + transforms) |
| `training.log` | Full timestamped log |
| `training_history.csv` | Epoch-by-epoch loss and accuracy |
| `lr_finder_plot.png` | LR finder curve (with `--lr-finder`) |

**Expected training time:**

| Hardware | ~Time (3 classes, 150 img/class) |
|---|---|
| NVIDIA RTX 3080 | 3â€“6 minutes |
| NVIDIA GTX 1060 | 10â€“15 minutes |
| Apple M2 (MPS) | 8â€“12 minutes |
| CPU only | 60â€“120 minutes |

---

## ğŸ”® Prediction

```bash
# Single image â€” pretty output
python predict.py --image path/to/image.jpg

# Single image â€” JSON output
python predict.py --image path/to/image.jpg --output-format json

# Multiple images
python predict.py --images img1.jpg img2.jpg img3.jpg

# Entire folder
python predict.py --folder data/test/

# Save results to file
python predict.py --folder data/test/ --output-format json --output-file results.json

# Force CPU
python predict.py --image img.jpg --cpu

# Confidence threshold (marks uncertain predictions)
python predict.py --image img.jpg --threshold 0.7
```

**Example output:**

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Image  : data/dataset/cat/cat_042.jpg
  Result : CAT  (98.21%)

             cat: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  98.2%  â—„
             dog: â–‘â–‘â–‘â–‘                             1.3%
            bird: â–‘                                0.5%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

---

## ğŸ“Š Evaluation

```bash
python evaluation.py

# Custom paths
python evaluation.py --model models/exported/classifier.pkl \
                     --data  data/dataset \
                     --output eval_report.json
```

Reports: top-1 accuracy, top-3 accuracy, per-class Precision / Recall / F1, confusion matrix.

---

## âš™ï¸ Configuration

All hyperparameters live in `config/config.yaml` â€” no code changes needed:

```yaml
model:
  architecture: "resnet50"   # resnet34 | resnet50 | efficientnet_b0 | efficientnet_b3

data:
  image_size:  224           # increase to 299+ for better accuracy (more VRAM)
  batch_size:  32            # reduce to 16 if GPU runs out of memory

training:
  head_epochs:     4         # Phase 1: head-only training
  finetune_epochs: 10        # Phase 2: full fine-tuning
  mixup_alpha:     0.4       # 0 to disable MixUp
  label_smoothing: 0.1       # 0 to disable label smoothing
```

---

## ğŸŒ REST API

```bash
# Install API dependencies
pip install fastapi uvicorn python-multipart

# Train the model first
python train.py

# Start the server
uvicorn api:app --host 0.0.0.0 --port 8080
```

**Endpoints:**

```bash
# Classify an image
curl -X POST http://localhost:8080/classify \
     -F "file=@cat.jpg"

# Health check
curl http://localhost:8080/health

# List classes
curl http://localhost:8080/classes
```

**JSON response:**

```json
{
  "image_path": "cat.jpg",
  "label": "cat",
  "confidence": 0.9821,
  "all_probs": {
    "cat": 0.9821,
    "dog": 0.0134,
    "bird": 0.0045
  },
  "top_3": [["cat", 0.9821], ["dog", 0.0134], ["bird", 0.0045]]
}
```

Interactive docs (Swagger UI): [http://localhost:8080/docs](http://localhost:8080/docs)

---

## ğŸ³ Docker

```bash
# Build
docker build -t image-classifier:latest .

# Run (mounts your local models/ directory)
docker run -p 8080:8080 \
           -v $(pwd)/models:/app/models \
           image-classifier:latest

# Test
curl http://localhost:8080/health
```

---

## ğŸ“ˆ Improving Accuracy

| Technique | Typical gain | How to enable |
|---|---|---|
| **More data** | +5â€“15% | Add images to `data/dataset/<class>/` |
| **Larger backbone** | +1â€“4% | `architecture: "efficientnet_b3"` in config |
| **Bigger input size** | +1â€“3% | `image_size: 299` in config |
| **LR finder** | +0.5â€“2% | `python train.py --lr-finder` |
| **Test-time augmentation** | +1â€“2% | See TTA section below |
| **Progressive resizing** | +1â€“2% | Train 128px â†’ 224px â†’ 320px |
| **More epochs** | varies | Increase `finetune_epochs` in config |

**Test-Time Augmentation (TTA):**

```python
# In your evaluation or predict script:
preds, targets = learn.tta(ds_idx=1)
# Averages predictions over augmented copies â€” free accuracy boost
```

---

## ğŸ›  Troubleshooting

| Problem | Likely cause | Fix |
|---|---|---|
| `CUDA out of memory` | Batch too large | Set `batch_size: 16` in config |
| `NaN loss during training` | LR too high | Use `--lr-finder` flag |
| `Accuracy < 60%` | Insufficient data | Add â‰¥ 200 images/class |
| `Model not found` on predict | Not trained yet | Run `python train.py` |
| `No module named fastai` | Wrong venv | `source .venv/bin/activate` |
| `FileNotFoundError: dataset` | Dataset missing | Run `python scripts/download_sample_data.py` |
| Very slow training on macOS | MPS not detected | Requires PyTorch â‰¥ 2.0 + macOS 12.3+ |

---

## ğŸ“‹ Expected Accuracy

| Images/class | Expected top-1 accuracy (ResNet-50) |
|---|---|
| 50  | 75â€“85% |
| 200 | 85â€“92% |
| 500 | 90â€“95% |
| 1000+ | 93â€“98% |

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgements

- [fast.ai](https://fast.ai) â€” high-level deep learning library
- [PyTorch](https://pytorch.org) â€” underlying tensor framework
- [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) â€” sample data
- Leslie Smith â€” Learning Rate Range Test (2017)
